{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac74869c-7ed1-401c-94e6-f0ac931d3c0d",
   "metadata": {},
   "source": [
    "### 교차 검증 (Cross Validation)\n",
    "- 기존 방식에서는 데이터 세트에서 학습 데이터 세트와 테스트 데이터 세트를 분리한 뒤 모델 검증을 진행한다.\n",
    "- 교차 검증 시, 학습 데이터를 다시 분할하여 학습 데이터와 모델 성능을 1차 평가하는 검증 데이터로 나눈다.\n",
    "\n",
    "<img src=\"./images/cross_validation01.png\" width=\"500px\">\n",
    "\n",
    "#### 교차 검증의 장단점\n",
    "- 👍특정 데이터 세트에 대한 과적합 방지\n",
    "- 👍데이터 세트 규모가 적을 시 과소적합 방지\n",
    "- 👎모델 훈련, 모델 평가에 소요되는 시간 증가\n",
    "- 즉, 과적합을 피하고 하이퍼 파라미터를 튜닝함으로써 모델을 일반화하고 신뢰성을 증가시키기 위한 목적이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f730b87-f310-4d48-91c3-c6a922309e41",
   "metadata": {},
   "source": [
    "#### 교차 검증의 종류\n",
    "K-Fold\n",
    "- k개의 데이터 폴드 세트를 만든 뒤 k번만큼 학습과 검증 평가를 반복해서 수행하는 방식.\n",
    "- 학습 데이터와 검증 데이터를 정확히 자르기 때문에 타겟 데이터의 비중이 한 곳으로 치충될 수 있다.\n",
    "- 예를 들어, 0, 1, 2 중에서 0, 1, 두 가지만 잘라서 검증하게 되면 다른 하나의 타겟 데이터를 예측할 수 없게 된다.\n",
    "- Stratified K-Fold로 해결한다.\n",
    "\n",
    "Stratified K-Fold\n",
    "- K-Fold와 마찬가지로 k번 수행하지만, 학습 데이터 세트와 검증 데이터 세트가 가지는 타겟 분포도가 유사하도록 검증한다.\n",
    "- 타켓 데이터의 비중을 항상 똑같게 자르기 때문에 데이터가 한 곳으로 치중되는 것을 방지한다.\n",
    "\n",
    "<img src=\"./images/cross_validation02.png\" width=\"600px\">\n",
    "\n",
    "GridSearchCV\n",
    "- 교차 검증과 최족의 하이퍼 파라미터 튜닝을 한 번에 할 수 있는 객체이다\n",
    "- max_depth와 min_sample_split에 1차원 정수형 list를 전달하면, 2차원으로 결합하여 격자(Grid)를 만들고, 이 중 최적의 점을 찾아낸다.\n",
    "- 딥러닝에서는 학습 속도가 머신러닝에 비해 느리고, 레이어(층)가 깊어질 수록 조정해주어야 할 하이퍼 파라미터 값이 많아지기 때문에, RandomSearchCV에서 대략적인 범위를 찾은 다음, GridSearchCV로 디테일을 조정하는 방식을 사용한다.\n",
    "\n",
    "<img src=\"./images/grid_search_cv.png\" width=\"500px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69a14750-4f33-40a4-8840-5fac38c4dee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0         50\n",
       "1         50\n",
       "2         50\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "iris = load_iris()\n",
    "features = iris.data\n",
    "targets = iris.target\n",
    "\n",
    "target_df = pd.DataFrame(targets, columns=['target'])\n",
    "target_df.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78a89bd2-ee66-4ba9-bd29-a014d376d857",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "dtc = DecisionTreeClassifier(random_state=124, min_samples_leaf=6)\n",
    "kfold = KFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe47a564-1c11-439b-a892-fafc2e1db9d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "066c169d-22cf-4ca2-907a-a5dd5fb5d5e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 회차\n",
      "학습 타겟 데이터 분포: \n",
      "1    50\n",
      "2    50\n",
      "0    20\n",
      "Name: count, dtype: int64\n",
      "검증 타겟 데이터 분포: \n",
      "0    30\n",
      "Name: count, dtype: int64\n",
      "정확도 1.0\n",
      "2 회차\n",
      "학습 타겟 데이터 분포: \n",
      "2    50\n",
      "1    40\n",
      "0    30\n",
      "Name: count, dtype: int64\n",
      "검증 타겟 데이터 분포: \n",
      "0    20\n",
      "1    10\n",
      "Name: count, dtype: int64\n",
      "정확도 1.0\n",
      "3 회차\n",
      "학습 타겟 데이터 분포: \n",
      "0    50\n",
      "2    50\n",
      "1    20\n",
      "Name: count, dtype: int64\n",
      "검증 타겟 데이터 분포: \n",
      "1    30\n",
      "Name: count, dtype: int64\n",
      "정확도 0.8333\n",
      "4 회차\n",
      "학습 타겟 데이터 분포: \n",
      "0    50\n",
      "1    40\n",
      "2    30\n",
      "Name: count, dtype: int64\n",
      "검증 타겟 데이터 분포: \n",
      "2    20\n",
      "1    10\n",
      "Name: count, dtype: int64\n",
      "정확도 0.9333\n",
      "5 회차\n",
      "학습 타겟 데이터 분포: \n",
      "0    50\n",
      "1    50\n",
      "2    20\n",
      "Name: count, dtype: int64\n",
      "검증 타겟 데이터 분포: \n",
      "2    30\n",
      "Name: count, dtype: int64\n",
      "정확도 0.8333\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "\n",
    "for train_index, test_index in kfold.split(features):\n",
    "    # 분리\n",
    "    X_train, X_test = features[train_index], features[test_index]\n",
    "    y_train, y_test = targets[train_index], targets[test_index]\n",
    "\n",
    "    # 학습\n",
    "    dtc.fit(X_train, y_train)\n",
    "    prediction =  dtc.predict(X_test)\n",
    "\n",
    "\n",
    "    # 평가\n",
    "    accuracy = np.round(accuracy_score(y_test, prediction),4)\n",
    "\n",
    "    # 검증\n",
    "    train_targets = pd.DataFrame(y_train)\n",
    "    test_targets = pd.DataFrame(y_test)\n",
    "\n",
    "    count += 1\n",
    "    \n",
    "    print(f'{count} 회차')\n",
    "    print(f'학습 타겟 데이터 분포: \\n{train_targets.value_counts()}')\n",
    "    print(f'검증 타겟 데이터 분포: \\n{test_targets.value_counts()}')\n",
    "    print(f'정확도 {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8798aa01-613b-42c2-941c-84589d67f579",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "s_fold = StratifiedKFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "451b79ed-0702-45e7-bfa6-66354cdb0f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 회차\n",
      "학습 타겟 데이터 분포: \n",
      "0    40\n",
      "1    40\n",
      "2    40\n",
      "Name: count, dtype: int64\n",
      "검증 타겟 데이터 분포: \n",
      "0    10\n",
      "1    10\n",
      "2    10\n",
      "Name: count, dtype: int64\n",
      "정확도 0.9667\n",
      "2 회차\n",
      "학습 타겟 데이터 분포: \n",
      "0    40\n",
      "1    40\n",
      "2    40\n",
      "Name: count, dtype: int64\n",
      "검증 타겟 데이터 분포: \n",
      "0    10\n",
      "1    10\n",
      "2    10\n",
      "Name: count, dtype: int64\n",
      "정확도 0.9667\n",
      "3 회차\n",
      "학습 타겟 데이터 분포: \n",
      "0    40\n",
      "1    40\n",
      "2    40\n",
      "Name: count, dtype: int64\n",
      "검증 타겟 데이터 분포: \n",
      "0    10\n",
      "1    10\n",
      "2    10\n",
      "Name: count, dtype: int64\n",
      "정확도 0.9\n",
      "4 회차\n",
      "학습 타겟 데이터 분포: \n",
      "0    40\n",
      "1    40\n",
      "2    40\n",
      "Name: count, dtype: int64\n",
      "검증 타겟 데이터 분포: \n",
      "0    10\n",
      "1    10\n",
      "2    10\n",
      "Name: count, dtype: int64\n",
      "정확도 0.8667\n",
      "5 회차\n",
      "학습 타겟 데이터 분포: \n",
      "0    40\n",
      "1    40\n",
      "2    40\n",
      "Name: count, dtype: int64\n",
      "검증 타겟 데이터 분포: \n",
      "0    10\n",
      "1    10\n",
      "2    10\n",
      "Name: count, dtype: int64\n",
      "정확도 1.0\n",
      "평균 정확도: 0.94002\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "accuracy_list = []\n",
    "\n",
    "for train_index, test_index in s_fold.split(features, targets):\n",
    "    # 분리\n",
    "    X_train, X_test = features[train_index], features[test_index]\n",
    "    y_train, y_test = targets[train_index], targets[test_index]\n",
    "\n",
    "    # 학습\n",
    "    dtc.fit(X_train, y_train)\n",
    "    prediction =  dtc.predict(X_test)\n",
    "\n",
    "\n",
    "    # 평가\n",
    "    accuracy = np.round(accuracy_score(y_test, prediction),4)\n",
    "    accuracy_list.append(accuracy)\n",
    "\n",
    "    # 검증\n",
    "    train_targets = pd.DataFrame(y_train)\n",
    "    test_targets = pd.DataFrame(y_test)\n",
    "\n",
    "    count += 1\n",
    "    \n",
    "    print(f'{count} 회차')\n",
    "    print(f'학습 타겟 데이터 분포: \\n{train_targets.value_counts()}')\n",
    "    print(f'검증 타겟 데이터 분포: \\n{test_targets.value_counts()}')\n",
    "    print(f'정확도 {accuracy}')\n",
    "\n",
    "print(f'평균 정확도: {np.mean(accuracy_list)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e636177-d7a2-48a3-8e5c-93c9c50f56a6",
   "metadata": {},
   "source": [
    "#### 편하게 수행할 수 있는 교차 검증\n",
    "**cross_val_score(estimator, x, y, cv, scoring)**\n",
    "- estimator: classifier 종류 모델이면 내부적으로 startified K-Fold로 진행된다.\n",
    "- x: features\n",
    "- y: targets\n",
    "- cv: 폴드 세트 개수\n",
    "- scoring: 평가 함수, 정확도(accuracy)외에 다른 것은 다른 장에서 배운다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "517e61ba-2852-42e1-bcbc-9e66a8fc88cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.94\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "\n",
    "iris = load_iris()\n",
    "dtc = DecisionTreeClassifier(random_state=124, min_samples_leaf=6)\n",
    "\n",
    "featrues = iris.data\n",
    "targets = iris.target\n",
    "\n",
    "score = cross_val_score(dtc, features, targets, cv=5, scoring='accuracy')\n",
    "print(np.round(np.mean(score), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9acef227-6ee9-4ce1-9325-ec0e5cb01781",
   "metadata": {},
   "source": [
    "#### GridSearchCV\n",
    "**GridSearchCV(estimator, param_grid, cv, refit, return_train_score)**\n",
    "- estimator: 학습할 모델 객체 작성\n",
    "- param_grid: dict형태로 전달해야 하며, 주요 key값은 max_depth, min_samples_split이다.\n",
    "- cv: 폴드 세트 개수\n",
    "- refit: 최적의 하이퍼 파라미터로 전달한 모델 객체를 다시 훈련하고자 할 때 True를 전달한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37f8f49-3f6e-4415-a7c0-55819c801718",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be94a6e-7c83-44b1-ba8d-cf902e0e6266",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60a5960-4df9-42c0-a046-93057b84fa4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec98e052-40ad-40fc-9576-b57f5ebc98ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8515338-87b5-4f5b-ba83-0c6c29d27a76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
